# ==================================================================
# ìµœì¢… ë¸”ë Œë”© ë° í›„ì²˜ë¦¬(final.py) ë‹¨ë… ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ê²½ë¡œ ìˆ˜ì • ìµœì¢…ë³¸)
# ==================================================================
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¯¸ë¦¬ ìƒì„±ëœ ë‘ ê°œì˜ ì˜ˆì¸¡ íŒŒì¼ì„ ë¶ˆëŸ¬ì™€
# ë™ì  ë¸”ë Œë”©, ì•µì»¤ë§, ìŠ¤ë¬´ë”© í›„ì²˜ë¦¬ë¥¼ í†µí•´ ìµœì¢… ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
#
# ì‹¤í–‰ ì „ ì¤€ë¹„ë¬¼:
# - ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ í´ë”ì— ETTh1.csv íŒŒì¼ ìœ„ì¹˜
# - ì´ì „ ë‹¨ê³„ë“¤ì—ì„œ ìƒì„±ëœ ì˜ˆì¸¡ ê²°ê³¼ CSV íŒŒì¼ë“¤
# ==================================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import pandas as pd
import numpy as np
import os
from sklearn.metrics import mean_squared_error
import time

print("âœ… [1ë‹¨ê³„] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ê¸°ë³¸ ì„¤ì • ì™„ë£Œ.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_PATH = os.getcwd()

TRANSFORMER_PRED_PATH = os.path.join(BASE_PATH, "transformer_results", "submission_transformer.csv")
DLINEAR_ENSEMBLE_PATH = os.path.join(BASE_PATH, "dlinear_ensemble_results", "submission_conditional_ensemble.csv")

# ì •ë‹µ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ë³´í†µ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ìœ„ì¹˜)
GROUND_TRUTH_PATH = os.path.join(BASE_PATH, "ETTh1.csv")

# ìµœì¢… ê²°ê³¼ë¬¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
output_dir = os.path.join(BASE_PATH, "final_blending_results/")
os.makedirs(output_dir, exist_ok=True)

print(f"ğŸ“‚ Transformer ì˜ˆì¸¡ íŒŒì¼ ê²½ë¡œ: {TRANSFORMER_PRED_PATH}")
print(f"ğŸ“‚ DLinear ì•™ìƒë¸” ì˜ˆì¸¡ íŒŒì¼ ê²½ë¡œ: {DLINEAR_ENSEMBLE_PATH}")
print(f"ğŸ“‚ ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥ ê²½ë¡œ: {output_dir}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„(Grid) ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¸”ë Œë”© ê°€ì¤‘ì¹˜ íƒìƒ‰ ë²”ìœ„
short_term_weights_A = [0.4, 0.5, 0.6]  # ë‹¨ê¸° ì˜ˆì¸¡ì—ì„œ Transformer(A)ì— ë¶€ì—¬í•  ê°€ì¤‘ì¹˜
long_term_weights_A = [0.6, 0.7, 0.8]   # ì¥ê¸° ì˜ˆì¸¡ì—ì„œ Transformer(A)ì— ë¶€ì—¬í•  ê°€ì¤‘ì¹˜

# ìŠ¤ë¬´ë”© ê°€ì¤‘ì¹˜ íƒìƒ‰ ë²”ìœ„ (ê°€ì¥ ì˜í–¥ë ¥ì´ í° ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ ê°’ ìœ„ì£¼ë¡œ íŠœë‹)
strong_smoothing_configs = [
    [0.8, 0.5, 0.3],
    [0.7, 0.4, 0.2],
    [0.9, 0.6, 0.4]
]

print("\n" + "="*80)
print("â–¶ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
print(f"â–¶ ì´ {len(short_term_weights_A) * len(long_term_weights_A) * len(strong_smoothing_configs)}ê°œì˜ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
print("="*80 + "\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰ ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    # ë°ì´í„° ë¡œë“œ (ë£¨í”„ ì‹œì‘ ì „ í•œ ë²ˆë§Œ)
    pred_A = pd.read_csv(TRANSFORMER_PRED_PATH)
    pred_B = pd.read_csv(DLINEAR_ENSEMBLE_PATH)
    df_true = pd.read_csv(GROUND_TRUTH_PATH, parse_dates=['date'], index_col='date')
    date_col_name = pred_A.columns[0]
    
    # ì‹¤ì œ ê°’(Ground Truth) ë¯¸ë¦¬ ì¤€ë¹„
    gt_ots_list = []
    submit_times = pd.to_datetime(pred_A[date_col_name].values)
    for t in submit_times:
        gt_range = pd.date_range(start=t, periods=96, freq='H')
        gt_data = df_true.reindex(gt_range)['OT'].values
        gt_ots_list.append(gt_data)
    gt_ots_flat = np.concatenate(gt_ots_list)
    valid_indices = ~np.isnan(gt_ots_flat)
    gt_ots_clean = gt_ots_flat[valid_indices]
    
    print("âœ… ì˜ˆì¸¡ íŒŒì¼ ë° Ground Truth ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")

    results_log = []
    best_mse = float('inf')
    best_params = {}
    run_count = 0
    start_time = time.time()
    df_final = pd.DataFrame()

    # ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì— ëŒ€í•´ ë£¨í”„ ì‹¤í–‰
    for short_w_A in short_term_weights_A:
        for long_w_A in long_term_weights_A:
            for strong_smooth in strong_smoothing_configs:
                run_count += 1
                
                current_params = {
                    'short_A': short_w_A, 'long_A': long_w_A, 'strong_smooth': strong_smooth
                }
                print(f"--- [ì‹¤í–‰ {run_count}] íŒŒë¼ë¯¸í„°: {current_params} ---")

                # 1. ë™ì  ë¸”ë Œë”©
                short_w_B = 1 - short_w_A
                long_w_B = 1 - long_w_A
                short_term_blended = pred_A.iloc[:, 1:25].values * short_w_A + pred_B.iloc[:, 1:25].values * short_w_B
                long_term_blended = pred_A.iloc[:, 25:].values * long_w_A + pred_B.iloc[:, 25:].values * long_w_B
                blended_values = np.hstack([short_term_blended, long_term_blended])
                
                # 2. ì•µì»¤ë§ ë° ìŠ¤ë¬´ë”© í›„ì²˜ë¦¬
                final_predictions_list = []
                for i, row_values in enumerate(blended_values):
                    t0_timestamp = pd.to_datetime(pred_A.iloc[i, 0])
                    last_known_timestamp = t0_timestamp - pd.Timedelta(hours=1)
                    new_preds = row_values.copy()
                    
                    if last_known_timestamp in df_true.index:
                        anchor_value = df_true.loc[last_known_timestamp]['OT']
                        new_preds[0] = anchor_value
                        for j, weight in enumerate(strong_smooth):
                            if j + 1 < len(new_preds):
                                new_preds[j+1] = (new_preds[j] * weight) + (new_preds[j+1] * (1 - weight))
                    final_predictions_list.append(new_preds)

                # 3. ì„±ëŠ¥(MSE) ê³„ì‚°
                pred_flat = np.concatenate(final_predictions_list)
                y_pred_clean = pred_flat[valid_indices]
                mse = mean_squared_error(gt_ots_clean, y_pred_clean)
                print(f"  â–¶ MSE ê²°ê³¼: {mse:.6f}")

                # 4. ê²°ê³¼ ê¸°ë¡
                log_entry = current_params.copy()
                log_entry['MSE'] = mse
                results_log.append(log_entry)

                # 5. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸
                if mse < best_mse:
                    best_mse = mse
                    best_params = current_params
                    print(f"    â­ ìƒˆë¡œìš´ ìµœê³  ê¸°ë¡! (MSE: {best_mse:.6f})")
                    # ìµœê³  ì„±ëŠ¥ì¼ ë•Œì˜ ì˜ˆì¸¡ íŒŒì¼ ì €ì¥
                    df_final = pd.DataFrame(final_predictions_list, columns=pred_A.columns[1:])
                    df_final.insert(0, date_col_name, pred_A[date_col_name])

except FileNotFoundError as e:
    print(f"\nâŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("  ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ ê²½ë¡œ ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    print(f"  - í™•ì¸ ê²½ë¡œ 1: {TRANSFORMER_PRED_PATH}")
    print(f"  - í™•ì¸ ê²½ë¡œ 2: {DLINEAR_ENSEMBLE_PATH}")
except Exception as e:
    print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. ìµœì¢… ê²°ê³¼ ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if results_log:
    total_time = time.time() - start_time
    print("\n" + "="*80)
    print("â–¶ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"â–¶ ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  MSE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    results_df = pd.DataFrame(results_log)
    results_df = results_df.sort_values(by='MSE', ascending=True)
    
    # ì „ì²´ ê²°ê³¼ ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥
    full_log_filename = os.path.join(output_dir, "hyperparam_tuning_log.csv")
    results_df.to_csv(full_log_filename, index=False)
    print(f"âœ… ì „ì²´ íŠœë‹ ë¡œê·¸ê°€ '{full_log_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if not df_final.empty:
        best_submission_filename = os.path.join(output_dir, "submission_best_tuned.csv")
        df_final.to_csv(best_submission_filename, index=False)
        print(f"âœ… ìµœì  ì˜ˆì¸¡ íŒŒì¼ì´ '{best_submission_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print("\nğŸ† ìµœì¢… íŠœë‹ ê²°ê³¼ (ìƒìœ„ 5ê°œ)")
    print(results_df.head(5).to_string())
    
    print("\n" + "-"*50)
    print("ğŸš€ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ğŸš€")
    print(f"  - ë‹¨ê¸°(A) ê°€ì¤‘ì¹˜: {best_params.get('short_A')}")
    print(f"  - ì¥ê¸°(A) ê°€ì¤‘ì¹˜: {best_params.get('long_A')}")
    print(f"  - ìŠ¤ë¬´ë”© ê³„ìˆ˜: {best_params.get('strong_smooth')}")
    print(f"  - ìµœê³  MSE: {best_mse:.6f}")
    print(f"\nìµœì  ì˜ˆì¸¡ íŒŒì¼ì€ 'submission_best_tuned.csv' ì´ë¦„ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*80)
else:
    print("\nâŒ ê·¸ë¦¬ë“œ ì„œì¹˜ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")